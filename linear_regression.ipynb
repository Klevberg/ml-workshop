{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f9c6241",
   "metadata": {},
   "source": [
    "# Machine Learning Workshop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32b25da1-a18c-49f0-9539-20eafa8861e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from visualization import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3362137e",
   "metadata": {},
   "source": [
    "## Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febe6c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed for reproducibility\n",
    "SEED = 1\n",
    "\n",
    "# Generate a linear regression dataset\n",
    "X, y = datasets.make_regression(\n",
    "    n_samples=100, \n",
    "    n_features=1, \n",
    "    noise=10,\n",
    "    random_state=SEED,\n",
    "    bias=100.0\n",
    ")\n",
    "X = X.flatten() * 5 # Makes this example more interesting\n",
    "\n",
    "# Display first few samples of the dataset\n",
    "print(\"First 5 samples of the dataset:\")\n",
    "for i in range(5):\n",
    "    print(f\"X: {X[i]:.2f}, y: {y[i]:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7130785c",
   "metadata": {},
   "source": [
    "## Split the data into train, validation, and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c02848",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train, validation, and test sets (60%, 20%, 20%)\n",
    "X_train, X_temp, y_train, y_temp = None, None, None, None   # TODO\n",
    "X_val, X_test, y_val, y_test = None, None, None, None       # TODO\n",
    "\n",
    "# Scale the data using mean and standard deviation and using only training data statistics\n",
    "# X_mean = np.mean(X_train)\n",
    "# X_std = np.std(X_train)\n",
    "# X_train = (X_train - X_mean) / X_std\n",
    "# X_val = (X_val - X_mean) / X_std\n",
    "# X_test = (X_test - X_mean) / X_std\n",
    "\n",
    "# y_mean = np.mean(y_train)\n",
    "# y_std = np.std(y_train)\n",
    "# y_train = (y_train - y_mean) / y_std\n",
    "# y_val = (y_val - y_mean) / y_std\n",
    "# y_test = (y_test - y_mean) / y_std\n",
    "\n",
    "\n",
    "plot_train_val_data(X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a226982",
   "metadata": {},
   "source": [
    "## Functions for linear regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58599391",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X: np.ndarray, weights: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Compute predictions using linear regression\"\"\"\n",
    "    \n",
    "    ... # TODO\n",
    "\n",
    "\n",
    "def compute_loss_and_gradient(X: np.ndarray, y: np.ndarray, weights: np.ndarray) -> tuple[float, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Computes both MSE loss and its gradient in a single pass through the data\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (loss, gradient)\n",
    "    \"\"\"\n",
    "\n",
    "    ... # TODO\n",
    "\n",
    "\n",
    "def gradient_descent(\n",
    "    X: np.ndarray, \n",
    "    y: np.ndarray,\n",
    "    weights: np.ndarray=np.array([0, 0]),\n",
    "    learning_rate: float=0.1,\n",
    "    iterations: int=1000,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Iteratively updates the weights using the steepest descent method\n",
    "    \"\"\"\n",
    "    \n",
    "    ... # TODO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72d5743",
   "metadata": {},
   "source": [
    "## Run gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53334e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = None # TODO\n",
    "\n",
    "print(f\"Found weights: {weights}\")\n",
    "\n",
    "plot_linear_regression(X_train, y_train, weights, title=\"Linear Regression - Training Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd3fe5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_linear_regression(X_val, y_val, weights, title=\"Linear Regression - Validation Data\", scatter_color=\"orange\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d58cb55",
   "metadata": {},
   "source": [
    "## Run hyperparameter search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625c1811",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates = [] # TODO\n",
    "iterations = []     # TODO\n",
    "\n",
    "best_learning_rate = None\n",
    "best_iterations = None\n",
    "best_weights = None\n",
    "best_mse_val_loss = float('inf')\n",
    "\n",
    "plt.validation_results = {'lr': [], 'iterations': [], 'mse': []}\n",
    "\n",
    "for learning_rate in learning_rates:\n",
    "    for iteration in iterations:\n",
    "        weights = None                  # TODO\n",
    "        mse_val_loss, _ = None, None    # TODO\n",
    "        \n",
    "        # Store results for plotting\n",
    "        plt.validation_results['lr'].append(learning_rate)\n",
    "        plt.validation_results['iterations'].append(iteration)\n",
    "        plt.validation_results['mse'].append(mse_val_loss)\n",
    "        \n",
    "        print(f\"Learning rate = {learning_rate:.5f} | Iterations = {iteration}\\tMSE on validation set: {mse_val_loss}\")\n",
    "        \n",
    "        # Update best hyperparameters if current validation loss is lower\n",
    "        ... # TODO\n",
    "\n",
    "\n",
    "plot_validation_results(learning_rates, plt.validation_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b166952",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nBest learning rate: {best_learning_rate:.5f}\")\n",
    "print(f\"Best iterations: {best_iterations}\")\n",
    "print(f\"Best MSE on validation set: {best_mse_val_loss}\")\n",
    "\n",
    "plot_linear_regression(X_val, y_val, best_weights, title=\"Linear Regression - Validation Data\", scatter_color=\"orange\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff651f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_regression_progression(X_train, y_train, X_val, y_val, gradient_descent)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83ba885",
   "metadata": {},
   "source": [
    "## Evaluate on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f31eaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine train and validation sets\n",
    "X_combined = None # TODO\n",
    "y_combined = None # TODO\n",
    "\n",
    "# Train the model on combined data with best hyperparameters\n",
    "weights = None # TODO\n",
    "\n",
    "# Evaluate on test set\n",
    "mse_test_loss, _ = None, None # TODO\n",
    "print(f\"MSE on test set: {mse_test_loss}\")\n",
    "\n",
    "\n",
    "plot_linear_regression(X_test, y_test, weights, title=\"Linear Regression - Test Data\", scatter_color=\"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033640df",
   "metadata": {},
   "source": [
    "## Visualize gradient descent on loss surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30865f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_surface(X, y, compute_loss_and_gradient, dim='2d', lr=best_learning_rate, n_iter=best_iterations, init_weights=[0, 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a484b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_surface(X, y, compute_loss_and_gradient, dim='3d', lr=best_learning_rate, n_iter=best_iterations, init_weights=[0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fceb02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_surface(X, y, compute_loss_and_gradient, dim='3d', lr=0.005, n_iter=500, init_weights=[-150, 110])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4353dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_surface(X, y, compute_loss_and_gradient, dim='3d', lr=0.05, n_iter=100, init_weights=[-150, 110])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b558a94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
